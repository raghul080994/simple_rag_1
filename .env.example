# Backend configuration

# Chroma persistence directory (created automatically)
CHROMA_DB_DIR=./server/chroma_db
CHROMA_COLLECTION=rag_docs

# Ollama local API for embeddings (nomic embed only)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBED_MODEL=nomic-embed-text

# Retrieval and chunking
TOP_K=6
MIN_RELEVANCE=0.0
MAX_CONTEXT_CHARS=12000
CHUNK_CHARS=1200
CHUNK_OVERLAP=200

# LLM provider selection
LLM_PROVIDER=azure

# Azure OpenAI configuration
AZURE_OPENAI_ENDPOINT=https://YOUR_RESOURCE_NAME.openai.azure.com
AZURE_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_KEY=YOUR_AZURE_API_KEY
AZURE_API_VERSION=2024-06-01

# Frontend can use VITE_API_BASE_URL if needed (place in web/.env.local)
# VITE_API_BASE_URL=http://localhost:8000

